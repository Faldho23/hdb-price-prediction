{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05e369cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f70e3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_resale_data = pd.read_csv('data/processed/hdb_resale_data_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06fbbb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249857, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdb_resale_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "091bb1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>num_mrts_within_1km</th>\n",
       "      <th>min_dist_to_mrt_km</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>174</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1986</td>\n",
       "      <td>70</td>\n",
       "      <td>255000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>541</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1981</td>\n",
       "      <td>65</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>163</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>69.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>64</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>446</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1979</td>\n",
       "      <td>63</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.664472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>557</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>64</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month        town flat_type block        street_name storey_range  \\\n",
       "_id                                                                        \n",
       "1    2015-01  ANG MO KIO    3 ROOM   174   ANG MO KIO AVE 4     07 TO 09   \n",
       "2    2015-01  ANG MO KIO    3 ROOM   541  ANG MO KIO AVE 10     01 TO 03   \n",
       "3    2015-01  ANG MO KIO    3 ROOM   163   ANG MO KIO AVE 4     01 TO 03   \n",
       "4    2015-01  ANG MO KIO    3 ROOM   446  ANG MO KIO AVE 10     01 TO 03   \n",
       "5    2015-01  ANG MO KIO    3 ROOM   557  ANG MO KIO AVE 10     07 TO 09   \n",
       "\n",
       "     floor_area_sqm      flat_model  lease_commence_date  remaining_lease  \\\n",
       "_id                                                                         \n",
       "1              60.0        Improved                 1986               70   \n",
       "2              68.0  New Generation                 1981               65   \n",
       "3              69.0  New Generation                 1980               64   \n",
       "4              68.0  New Generation                 1979               63   \n",
       "5              68.0  New Generation                 1980               64   \n",
       "\n",
       "     resale_price  num_mrts_within_1km  min_dist_to_mrt_km  \n",
       "_id                                                         \n",
       "1        255000.0                    1            0.352915  \n",
       "2        275000.0                    0            0.816023  \n",
       "3        285000.0                    1            0.229604  \n",
       "4        290000.0                    1            0.664472  \n",
       "5        290000.0                    0            0.923402  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdb_resale_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3720faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "#hdb_resale_data = hdb_resale_data.drop(['month','block','street_name','lease_commence_date', 'num_mrts_within_1km'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c298e6",
   "metadata": {},
   "source": [
    "In this preprocessing step, we drop unnecessary columns. We remove lease_commence_date since its information is already reflected in remaining_lease. We also drop num_mrts_within_1km because it is less informative than min_dist_to_mrt_km. Most people, especially senior citizens, tend to care primarily about the shortest distance to the nearest MRT rather than the total number of MRT stations in the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65dbe9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20507ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessor(numerical_cols, categorical_cols):\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c3dbb",
   "metadata": {},
   "source": [
    "<h2> Basic Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "603fb983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "218144ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7813594",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(hdb_resale_data['resale_price'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1112df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 score: 0.7575195793383349\n",
      "Average RMSE: 0.16793482289514844\n"
     ]
    }
   ],
   "source": [
    "numerical_columns_linreg = hdb_resale_data.select_dtypes(include=['int64', 'float64']).columns.drop(['resale_price', 'lease_commence_date', 'num_mrts_within_1km'])\n",
    "categorical_columns_linreg = hdb_resale_data.select_dtypes(include=['object', 'category']).columns.drop(['month', 'block'])\n",
    "\n",
    "preprocessor_linreg = create_preprocessor(numerical_columns_linreg, categorical_columns_linreg)\n",
    "\n",
    "X_linreg = hdb_resale_data.drop(['month', 'block', 'resale_price', 'lease_commence_date', 'num_mrts_within_1km'], axis=1)\n",
    "\n",
    "X_processed_linreg = preprocessor_linreg.fit_transform(X_linreg)\n",
    "\n",
    "linreg_model = LinearRegression()\n",
    "\n",
    "GridSearchCV(linreg_model, param_grid=[], cv=kf, scoring='r2')\n",
    "\n",
    "scores = cross_val_score(linreg_model, X_processed_linreg, y, cv=kf, scoring='r2') \n",
    "\n",
    "rmse_scores = cross_val_score(linreg_model, X_processed_linreg,  y, cv=kf,\n",
    "                              scoring=make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred))))\n",
    "\n",
    "print(\"Average R2 score:\", np.mean(scores))\n",
    "print(\"Average RMSE:\", np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8708e",
   "metadata": {},
   "source": [
    "<h2> Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5076a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcf81835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'alpha': 100}\n",
      "Best R²: 0.7457609188504882\n"
     ]
    }
   ],
   "source": [
    "numerical_columns_ridge = hdb_resale_data.select_dtypes(include=['int64', 'float64']).columns.drop(['resale_price'])\n",
    "categorical_columns_ridge = hdb_resale_data.select_dtypes(include=['object', 'category']).columns.drop(['month', 'block'])\n",
    "\n",
    "preprocessor_ridge = create_preprocessor(numerical_columns_ridge, categorical_columns_ridge)\n",
    "\n",
    "X_ridge = hdb_resale_data.drop(['month', 'block'], axis=1)\n",
    "\n",
    "X_processed_ridge = preprocessor_ridge.fit_transform(X_ridge)\n",
    "\n",
    "params_ridge = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "ridge_model = Ridge()\n",
    "\n",
    "grid_ridge = GridSearchCV(ridge_model, params_ridge, cv=5, scoring='r2')\n",
    "grid_ridge.fit(X_processed_ridge, y)\n",
    "\n",
    "print(\"Best alpha:\", grid_ridge.best_params_)\n",
    "print(\"Best R²:\", grid_ridge.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0b348",
   "metadata": {},
   "source": [
    "<h2> Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7260bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=15.7min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=15.2min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=15.3min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=15.0min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=100; total time=14.5min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=29.1min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=29.0min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=29.5min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=29.1min\n",
      "[CV] END max_depth=None, min_samples_split=2, n_estimators=200; total time=28.4min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=10.3min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=10.2min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=10.2min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=10.2min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=11.7min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=23.0min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=21.2min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=21.5min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=21.2min\n",
      "[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=21.7min\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best R²: 0.9615249535342307\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Training Random Forest Regressor\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "X_processed_rf = X_processed_linreg\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10],\n",
    "    'min_samples_split': [2]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    rf_model, \n",
    "    param_grid=params_rf,\n",
    "    cv=kf,\n",
    "    scoring='r2',\n",
    "    n_jobs=1, \n",
    "    verbose=2)\n",
    "\n",
    "grid_rf.fit(X_processed_rf, y)\n",
    "\n",
    "print(\"Best parameters:\", grid_rf.best_params_)\n",
    "print(\"Best R²:\", grid_rf.best_score_)\n",
    "\n",
    "# Save\n",
    "joblib.dump(grid_rf, \"models/random_forest_gridsearch.pkl\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0449eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: RandomForestRegressor(n_estimators=200, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Load Random Forest model\n",
    "grid_rf = joblib.load(\"models/random_forest_gridsearch.pkl\")\n",
    "print(\"Best parameters:\", grid_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4323da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R²: 0.9934\n",
      "Test R² : 0.9932\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest R² : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# --- Learning curve ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m train_sizes, train_scores, test_scores = \u001b[43mlearning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbest_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_processed_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Compute mean/std\u001b[39;00m\n\u001b[32m     30\u001b[39m train_mean = np.mean(train_scores, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git\\my-projects\\hdb-price-prediction\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git\\my-projects\\hdb-price-prediction\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:2065\u001b[39m, in \u001b[36mlearning_curve\u001b[39m\u001b[34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params, params)\u001b[39m\n\u001b[32m   2062\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m n_train_samples \u001b[38;5;129;01min\u001b[39;00m train_sizes_abs:\n\u001b[32m   2063\u001b[39m         train_test_proportions.append((train[:n_train_samples], test))\n\u001b[32m-> \u001b[39m\u001b[32m2065\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2073\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2075\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2076\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2078\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2081\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_test_proportions\u001b[49m\n\u001b[32m   2082\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2083\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m   2084\u001b[39m results = _aggregate_score_dicts(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git\\my-projects\\hdb-price-prediction\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git\\my-projects\\hdb-price-prediction\\venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git\\my-projects\\hdb-price-prediction\\venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Git\\my-projects\\hdb-price-prediction\\venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_processed_rf = X_processed_linreg\n",
    "\n",
    "# Instead of retraining, just grab the trained best model\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# Split into train and test for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed_rf, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check R²\n",
    "train_r2 = r2_score(y_train, best_rf.predict(X_train))\n",
    "test_r2 = r2_score(y_test, best_rf.predict(X_test))\n",
    "\n",
    "print(f\"Train R²: {train_r2:.4f}\")\n",
    "print(f\"Test R² : {test_r2:.4f}\")\n",
    "\n",
    "# --- Learning curve ---\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_rf, X_processed_rf, y, cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 6),\n",
    "    scoring=\"r2\"\n",
    ")\n",
    "\n",
    "# Compute mean/std\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', label=\"Training R²\")\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
    "\n",
    "plt.plot(train_sizes, test_mean, 'o-', label=\"Validation R²\")\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.ylabel(\"R² Score\")\n",
    "plt.title(\"Learning Curve for Random Forest (best model)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99300397",
   "metadata": {},
   "source": [
    "<h2> XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7766fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500, 'subsample': 0.8}\n",
      "Best R²: 0.8005152323989645\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Training Random Forest Regressor\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "'''\n",
    "X_processed_xgb = X_processed_linreg\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8]\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    xgb_model, \n",
    "    param_grid=param_grid_xgb, \n",
    "    cv=5, \n",
    "    scoring='r2', \n",
    "    n_jobs=2,\n",
    "    verbose=2)\n",
    "\n",
    "grid_xgb.fit(X_processed_xgb, y)\n",
    "\n",
    "print(\"Best parameters:\", grid_xgb.best_params_)\n",
    "print(\"Best R²:\", grid_xgb.best_score_)\n",
    "\n",
    "joblib.dump(grid_xgb, \"models/xgb_gridsearch.pkl\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a48d507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
      "             n_jobs=None, num_parallel_tree=None, ...)\n"
     ]
    }
   ],
   "source": [
    "# Load XGB model\n",
    "grid_xgb = joblib.load(\"models/xgb_gridsearch.pkl\")\n",
    "print(\"Best parameters:\", grid_xgb.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
